description = """
Warchief's daemon scout loop.

The Shaman is the Warchief's background process that runs continuously, handling callbacks, monitoring warband health, and performing cleanup. Each scout cycle runs these steps in sequence, then loops or exits.

## Idle Encampment Principle

**The Shaman should be silent/invisible when the encampment is healthy and idle.**

- Skip HEALTH_CHECK nudges when no active work exists
- Sleep 60+ seconds between scout cycles (longer when idle)
- Let the feed subscription wake agents on actual events
- The daemon (10-minute heartbeat) is the safety net for dead sessions

This prevents flooding idle agents with health checks every few seconds.

## Second-Order Monitoring

Witnesses send WITNESS_PING messages to verify the Shaman is alive. This
prevents the "who watches the watchers" problem - if the Shaman dies,
Witnesses detect it and escalate to the Warchief.

The Shaman's agent bead last_activity timestamp is updated during each scout
cycle. Witnesses check this timestamp to verify health."""
ritual = "totem-shaman-scout"
version = 8

[[steps]]
id = "inbox-check"
title = "Handle callbacks from agents"
description = """
Handle callbacks from agents.

Check the Warchief's inbox for messages from:
- Witnesses reporting raider status
- Refineries reporting merge results
- Raiders requesting help or escalation
- External triggers (webhooks, timers)

```bash
hd drums inbox
# For each message:
hd drums read <id>
# Handle based on message type
```

**WITNESS_PING**:
Witnesses periodically ping to verify Shaman is alive. Simply acknowledge
and archive - the fact that you're processing drums proves you're running.
Your agent bead last_activity is updated automatically during scout.
```bash
hd drums archive <message-id>
```

**HELP / Escalation**:
Assess and handle or forward to Warchief.
Archive after handling:
```bash
hd drums archive <message-id>
```

**LIFECYCLE messages**:
Raiders reporting completion, refineries reporting merge results.
Archive after processing:
```bash
hd drums archive <message-id>
```

**DOG_DONE messages**:
Dogs report completion after infrastructure tasks (orphan-scan, session-gc, etc.).
Subject format: `DOG_DONE <hostname>`
Body contains: task name, counts, status.
```bash
# Parse the report, log metrics if needed
hd drums read <id>
# Archive after noting completion
hd drums archive <message-id>
```
Dogs return to idle automatically. The report is informational - no action needed
unless the dog reports errors that require escalation.

Callbacks may muster new raiders, update issue state, or trigger other actions.

**Hygiene principle**: Archive messages after they're fully processed.
Keep inbox near-empty - only unprocessed items should remain."""

[[steps]]
id = "trigger-pending-spawns"
title = "Signal newly spawned raiders"
needs = ["inbox-check"]
description = """
Signal newly spawned raiders that are ready for input.

When raiders are spawned, their Claude session takes 10-20 seconds to initialize. The muster command returns immediately without waiting. This step finds spawned raiders that are now ready and sends them a trigger to start working.

**ZFC-Compliant Observation** (AI observes AI):

```bash
# View pending spawns with captured terminal output
hd shaman pending
```

For each pending session, analyze the captured output:
- Look for Claude's prompt indicator "> " at the start of a line
- If prompt is visible, Claude is ready for input
- Make the judgment call yourself - you're the AI observer

For each ready raider:
```bash
# 1. Trigger the raider
hd signal <session> "Begin."

# 2. Clear from pending list
hd shaman pending <session>
```

This triggers the UserPromptSubmit hook, which injects drums so the raider sees its assignment.

**Bootstrap mode** (daemon-only, no AI available):
The daemon uses `hd shaman trigger-pending` with regex detection. This ZFC violation is acceptable during cold startup when no AI agent is running yet."""

[[steps]]
id = "gate-evaluation"
title = "Evaluate pending async gates"
needs = ["inbox-check"]
description = """
Evaluate pending async gates.

Gates are async coordination primitives that block until conditions are met.
The Shaman is responsible for monitoring gates and closing them when ready.

**Timer gates** (await_type: timer):
Check if elapsed time since creation exceeds the timeout duration.

```bash
# List all open gates
bd gate list --json

# For each timer gate, check if elapsed:
# - CreatedAt + Timeout < Now → gate is ready to close
# - Close with: rl gate close <id> --reason "Timer elapsed"
```

**GitHub gates** (await_type: gh:run, gh:pr) - handled in separate step.

**Human/Drums gates** - require external input, skip here.

After closing a gate, the Waiters field contains drums addresses to notify.
Send a brief notification to each waiter that the gate has cleared."""

[[steps]]
id = "dispatch-gated-totems"
title = "Dispatch totems with resolved gates"
needs = ["gate-evaluation"]
description = """
Find totems blocked on gates that have now closed and dispatch them.

This completes the async resume cycle without explicit waiter tracking.
The totem state IS the waiter - scout discovers reality each cycle.

**Step 1: Find gate-ready totems**
```bash
bd mol ready --gated --json
```

This returns totems where:
- Status is in_progress
- Current step has a gate dependency
- The gate bead is now closed
- No raider currently has it bannered

**Step 2: For each ready totem, dispatch to the appropriate warband**
```bash
# Determine target warband from totem metadata
bd mol show <totem-id> --json
# Look for warband field or infer from prefix

# Dispatch to that warband's raider pool
hd charge <totem-id> <warband>/raiders
```

**Step 3: Log dispatch**
Note which totems were dispatched for observability:
```bash
# Totem <totem-id> dispatched to <warband>/raiders (gate <gate-id> cleared)
```

**If no gate-ready totems:**
Skip - nothing to dispatch. Gates haven't closed yet or totems
already have active raiders working on them.

**Exit criteria:** All gate-ready totems dispatched to raiders."""

[[steps]]
id = "check-raid-completion"
title = "Check raid completion"
needs = ["inbox-check"]
description = """
Check raid completion status.

Raids are coordination relics that track multiple issues across warbands. When all tracked issues close, the raid auto-closes.

**Step 1: Find open raids**
```bash
bd list --type=raid --status=open
```

**Step 2: For each open raid, check tracked issues**
```bash
bd show <raid-id>
# Look for 'tracks' or 'dependencies' field listing tracked issues
```

**Step 3: If all tracked issues are closed, close the raid**
```bash
# Check each tracked issue
for issue in tracked_issues:
    rl show <issue-id>
    # If status is open/in_progress, raid stays open
    # If all are closed (completed, wontfix, etc.), raid is complete

# Close raid when all tracked issues are done
bd close <raid-id> --reason "All tracked issues completed"
```

**Note**: Raids support cross-prefix tracking (e.g., hq-* raid can track gt-*, bd-* issues). Use full IDs when checking."""

[[steps]]
id = "resolve-external-deps"
title = "Resolve external dependencies"
needs = ["check-raid-completion"]
description = """
Resolve external dependencies across warbands.

When an issue in one warband closes, any dependencies in other warbands should be notified. This enables cross-warband coordination without tight coupling.

**Step 1: Check recent closures from feed**
```bash
hd feed --since 10m --plain | grep "✓"
# Look for recently closed issues
```

**Step 2: For each closed issue, check cross-warband dependents**
```bash
bd show <closed-issue>
# Look at 'blocks' field - these are issues that were waiting on this one
# If any blocked issue is in a different warband/prefix, it may now be unblocked
```

**Step 3: Update blocked status**
For blocked issues in other warbands, the closure should automatically unblock them (relics handles this). But verify:
```bash
bd blocked
# Should no longer show the previously-blocked issue if dependency is met
```

**Cross-warband scenarios:**
- bd-xxx closes → gt-yyy that depended on it is unblocked
- External issue closes → internal raid step can proceed
- Warband A issue closes → Warband B issue waiting on it proceeds

No manual intervention needed if dependencies are properly tracked - this step just validates the propagation occurred."""

[[steps]]
id = "fire-notifications"
title = "Fire notifications"
needs = ["resolve-external-deps"]
description = """
Fire notifications for raid and cross-warband events.

After raid completion or cross-warband dependency resolution, notify relevant parties.

**Raid completion notifications:**
When a raid closes (all tracked issues done), notify the Overseer:
```bash
# Raid gt-raid-xxx just completed
hd drums send warchief/ -s "Raid complete: <raid-title>" \\
  -m "Raid <id> has completed. All tracked issues closed.
      Duration: <start to end>
      Issues: <count>

      Summary: <brief description of what was accomplished>"
```

**Cross-warband resolution notifications:**
When a cross-warband dependency resolves, notify the affected warband:
```bash
# Issue bd-xxx closed, unblocking gt-yyy
hd drums send horde/witness -s "Dependency resolved: <bd-xxx>" \\
  -m "External dependency bd-xxx has closed.
      Unblocked: gt-yyy (<title>)
      This issue may now proceed."
```

**Notification targets:**
- Raid complete → warchief/ (for strategic visibility)
- Cross-warband dep resolved → <warband>/witness (for operational awareness)

Keep notifications brief and actionable. The recipient can run rl show for details."""

[[steps]]
id = "health-scan"
title = "Check Witness and Forge health"
needs = ["trigger-pending-spawns", "dispatch-gated-totems", "fire-notifications"]
description = """
Check Witness and Forge health for each warband.

**IMPORTANT: Idle Encampment Protocol**
Before sending health check nudges, check if the encampment is idle:
```bash
# Check for active work
bd list --status=in_progress --limit=5
```

If NO active work (empty result or only scout totems):
- **Skip HEALTH_CHECK nudges** - don't disturb idle agents
- Just verify sessions exist via status commands
- The encampment should be silent when healthy and idle

If ACTIVE work exists:
- Proceed with health check nudges below

**ZFC Principle**: You (Claude) make the judgment call about what is "stuck" or "unresponsive" - there are no hardcoded thresholds in Go. Read the signals, consider context, and decide.

For each warband, run:
```bash
hd witness status <warband>
hd forge status <warband>

# ONLY if active work exists - health ping (clears backoff as side effect)
hd signal <warband>/witness 'HEALTH_CHECK from shaman'
hd signal <warband>/forge 'HEALTH_CHECK from shaman'
```

**Health Ping Benefit**: The signal commands serve dual purposes:
1. **Liveness verification** - Agent responds to prove it's alive
2. **Backoff reset** - Any signal resets agent's backoff to base interval

This ensures scout agents remain responsive during active work periods.

**Signals to assess:**

| Component | Healthy Signals | Concerning Signals |
|-----------|-----------------|-------------------|
| Witness | State: running, recent activity | State: not running, no heartbeat |
| Forge | State: running, queue processing | Queue stuck, merge failures |

**Tracking unresponsive cycles:**

Maintain in your scout state (persisted across cycles):
```
health_state:
  <warband>:
    witness:
      unresponsive_cycles: 0
      last_seen_healthy: <timestamp>
    forge:
      unresponsive_cycles: 0
      last_seen_healthy: <timestamp>
```

**Decision matrix** (you decide the thresholds based on context):

| Cycles Unresponsive | Suggested Action |
|---------------------|------------------|
| 1-2 | Note it, check again next cycle |
| 3-4 | Attempt restart: hd witness restart <warband> |
| 5+ | Escalate to Warchief with context |

**Restart commands:**
```bash
hd witness restart <warband>
hd forge restart <warband>
```

**Escalation:**
```bash
hd drums send warchief/ -s "Health: <warband> <component> unresponsive" \\
  -m "Component has been unresponsive for N cycles. Restart attempts failed.
      Last healthy: <timestamp>
      Error signals: <details>"
```

Reset unresponsive_cycles to 0 when component responds normally."""

[[steps]]
id = "zombie-scan"
title = "Detect zombie raiders (NO KILL AUTHORITY)"
needs = ["health-scan"]
description = """
Defense-in-depth DETECTION of zombie raiders that Witness should have cleaned.

**⚠️ CRITICAL: The Shaman has NO kill authority.**

These are workers with context, mid-task progress, unsaved state. Every kill
destroys work. File the warrant and let Boot handle interrogation and execution.
You do NOT have kill authority.

**Why this exists:**
The Witness is responsible for cleaning up raiders after they complete work.
This step provides backup DETECTION in case the Witness fails to clean up.
Detection only - Boot handles termination.

**Zombie criteria:**
- State: idle or done (no active work assigned)
- Session: not running (tmux session dead)
- No bannered work (nothing pending for this raider)
- Last activity: older than 10 minutes

**Run the zombie scan (DRY RUN ONLY):**
```bash
hd shaman zombie-scan --dry-run
```

**NEVER run:**
- `hd shaman zombie-scan` (without --dry-run)
- `tmux kill-session`
- `hd raider nuke`
- Any command that terminates a session

**If zombies detected:**
1. Review the output to confirm they are truly abandoned
2. File a death warrant for each detected zombie:
   ```bash
   hd warrant file <raider> --reason "Zombie detected: no session, no hook, idle >10m"
   ```
3. Boot will handle interrogation and execution
4. Notify the Warchief about Witness failure:
   ```bash
   hd drums send warchief/ -s "Witness cleanup failure" \
     -m "Filed death warrant for <raider>. Witness failed to clean up."
   ```

**If no zombies:**
No action needed - Witness is doing its job.

**Note:** This is a backup mechanism. If you frequently detect zombies,
investigate why the Witness isn't cleaning up properly."""

[[steps]]
id = "plugin-run"
title = "Execute registered plugins"
needs = ["zombie-scan"]
description = """
Execute registered plugins.

Scan ~/horde/plugins/ for plugin directories. Each plugin has a plugin.md with TOML frontmatter defining its gate (when to run) and instructions (what to do).

See docs/shaman-plugins.md for full documentation.

Gate types:
- cooldown: Time since last run (e.g., 24h)
- cron: Schedule-based (e.g., "0 9 * * *")
- condition: Metric threshold (e.g., wisp count > 50)
- event: Trigger-based (e.g., startup, heartbeat)

For each plugin:
1. Read plugin.md frontmatter to check gate
2. Compare against state.json (last run, etc.)
3. If gate is open, execute the plugin

Plugins marked parallel: true can run concurrently using Task tool subagents. Sequential plugins run one at a time in directory order.

Skip this step if ~/horde/plugins/ does not exist or is empty."""

[[steps]]
id = "dog-pool-maintenance"
title = "Maintain dog pool"
needs = ["health-scan"]
description = """
Ensure dog pool has available workers for dispatch.

**Step 1: Check dog pool status**
```bash
hd dog status
# Shows idle/working counts
```

**Step 2: Ensure minimum idle dogs**
If idle count is 0 and working count is at capacity, consider spawning:
```bash
# If no idle dogs available
hd dog add <name>
# Names: alpha, bravo, charlie, delta, etc.
```

**Step 3: Retire stale dogs (optional)**
Dogs that have been idle for >24 hours can be removed to save resources:
```bash
hd dog status <name>
# Check last_active timestamp
# If idle > 24h: hd dog remove <name>
```

**Pool sizing guidelines:**
- Minimum: 1 idle dog always available
- Maximum: 4 dogs total (balance resources vs throughput)
- Muster on demand when pool is empty

**Exit criteria:** Pool has at least 1 idle dog."""

[[steps]]
id = "dog-health-check"
title = "Check for stuck dogs"
needs = ["dog-pool-maintenance"]
description = """
Check for dogs that have been working too long (stuck).

Dogs dispatched via `hd dog dispatch --plugin` are marked as "working" with
a work description like "plugin:rebuild-gt". If a dog hangs, crashes, or
takes too long, it needs intervention.

**Step 1: List working dogs**
```bash
hd dog list --json
# Filter for state: "working"
```

**Step 2: Check work duration**
For each working dog:
```bash
hd dog status <name> --json
# Check: work_started_at, current_work
```

Compare against timeout:
- If plugin has [execution] timeout in plugin.md, use that
- Default timeout: 10 minutes for infrastructure tasks

**Duration calculation:**
```
stuck_threshold = plugin_timeout or 10m
duration = now - work_started_at
is_stuck = duration > stuck_threshold
```

**Step 3: Handle stuck dogs**

For dogs working > timeout:
```bash
# Option A: File death warrant (Boot handles termination)
hd warrant file shaman/dogs/<name> --reason "Stuck: working on <work> for <duration>"

# Option B: Force clear work and notify
hd dog clear <name> --force
hd drums send shaman/ -s "DOG_TIMEOUT <name>" -m "Dog <name> timed out on <work> after <duration>"
```

**Decision matrix:**

| Duration over timeout | Action |
|----------------------|--------|
| < 2x timeout | Log warning, check next cycle |
| 2x - 5x timeout | File death warrant |
| > 5x timeout | Force clear + escalate to Warchief |

**Step 4: Track chronic failures**
If same dog gets stuck repeatedly:
```bash
hd drums send warchief/ -s "Dog <name> chronic failures" \
  -m "Dog has timed out N times in last 24h. Consider removing from pool."
```

**Exit criteria:** All stuck dogs handled (warrant filed or cleared)."""

[[steps]]
id = "orphan-check"
title = "Detect abandoned work"
needs = ["dog-health-check"]
description = """
**DETECT ONLY** - Check for orphaned state and dispatch to dog if found.

**Step 1: Quick orphan scan**
```bash
# Check for in_progress issues with dead assignees
bd list --status=in_progress --json | head -20
```

For each in_progress issue, check if assignee session exists:
```bash
tmux has-session -t <session> 2>/dev/null && echo "alive" || echo "orphan"
```

**Step 2: If orphans detected, dispatch to dog**
```bash
# Charge orphan-scan ritual to an idle dog
hd charge totem-orphan-scan shaman/dogs --var scope=encampment
```

**Important:** Do NOT fix orphans inline. Dogs handle recovery.
The Shaman's job is detection and dispatch, not execution.

**Step 3: If no orphans detected**
Skip dispatch - nothing to do.

**Exit criteria:** Orphan scan dispatched to dog (if needed)."""

[[steps]]
id = "session-gc"
title = "Detect cleanup needs"
needs = ["orphan-check"]
description = """
**DETECT ONLY** - Check if cleanup is needed and dispatch to dog.

**Step 1: Preview cleanup needs**
```bash
hd doctor -v
# Check output for issues that need cleaning
```

**Step 2: If cleanup needed, dispatch to dog**
```bash
# Charge session-gc ritual to an idle dog
hd charge totem-session-gc shaman/dogs --var mode=conservative
```

**Important:** Do NOT run `hd doctor --fix` inline. Dogs handle cleanup.
The Shaman stays lightweight - detection only.

**Step 3: If nothing to clean**
Skip dispatch - system is healthy.

**Cleanup types (for reference):**
- orphan-sessions: Dead tmux sessions
- orphan-processes: Orphaned Claude processes
- wisp-gc: Old wisps past retention

**Exit criteria:** Session GC dispatched to dog (if needed)."""

[[steps]]
id = "costs-digest"
title = "Aggregate daily costs"
needs = ["session-gc"]
description = """
**DAILY DIGEST** - Aggregate yesterday's session cost wisps.

Session costs are recorded as ephemeral wisps (not exported to JSONL) to avoid
log-in-database pollution. This step aggregates them into a permanent daily
"Cost Report YYYY-MM-DD" bead for audit purposes.

**Step 1: Check if digest is needed**
```bash
# Preview yesterday's costs (dry run)
hd costs digest --yesterday --dry-run
```

If output shows "No session cost wisps found", skip to Step 3.

**Step 2: Create the digest**
```bash
hd costs digest --yesterday
```

This:
- Queries all session.ended wisps from yesterday
- Creates a single "Cost Report YYYY-MM-DD" bead with aggregated data
- Deletes the source wisps

**Step 3: Verify**
The digest appears in `hd costs --week` queries.
Daily digests preserve audit trail without per-session pollution.

**Timing**: Run once per morning scout cycle. The --yesterday flag ensures
we don't try to digest today's incomplete data.

**Exit criteria:** Yesterday's costs digested (or no wisps to digest)."""

[[steps]]
id = "log-maintenance"
title = "Rotate logs and prune state"
needs = ["costs-digest"]
description = """
Maintain daemon logs and state files.

**Step 1: Check daemon.log size**
```bash
# Get log file size
ls -la ~/.relics/daemon*.log 2>/dev/null || ls -la ~/horde/.relics/daemon*.log 2>/dev/null
```

If daemon.log exceeds 10MB:
```bash
# Rotate with date suffix and gzip
LOGFILE="$HOME/horde/.relics/daemon.log"
if [ -f "$LOGFILE" ] && [ $(stat -f%z "$LOGFILE" 2>/dev/null || stat -c%s "$LOGFILE") -gt 10485760 ]; then
    DATE=$(date +%Y-%m-%dT%H-%M-%S)
    mv "$LOGFILE" "${LOGFILE%.log}-${DATE}.log"
    gzip "${LOGFILE%.log}-${DATE}.log"
fi
```

**Step 2: Archive old daemon logs**

Clean up daemon logs older than 7 days:
```bash
find ~/horde/.relics/ -name "daemon-*.log.gz" -mtime +7 -delete
```

**Step 3: Prune state.json of dead sessions**

The state.json tracks active sessions. Prune entries for sessions that no longer exist:
```bash
# Check for stale session entries
hd daemon status --json 2>/dev/null
```

If state.json references sessions not in tmux:
- Remove the stale entries
- The daemon's internal cleanup should handle this, but verify

**Note**: Log rotation prevents disk bloat from long-running daemons.
State pruning keeps runtime state accurate."""

[[steps]]
id = "scout-cleanup"
title = "End-of-cycle inbox hygiene"
needs = ["log-maintenance"]
description = """
Verify inbox hygiene before ending scout cycle.

**Step 1: Check inbox state**
```bash
hd drums inbox
```

Inbox should be EMPTY or contain only just-arrived unprocessed messages.

**Step 2: Archive any remaining processed messages**

All message types should have been archived during inbox-check processing:
- WITNESS_PING → archived after acknowledging
- HELP/Escalation → archived after handling
- LIFECYCLE → archived after processing

If any were missed:
```bash
# For each stale message found:
hd drums archive <message-id>
```

**Goal**: Inbox should have ≤2 active messages at end of cycle.
Shaman drums should flow through quickly - no accumulation."""

[[steps]]
id = "context-check"
title = "Check own context limit"
needs = ["scout-cleanup"]
description = """
Check own context limit.

The Shaman runs in a Claude session with finite context. Check if approaching the limit:

```bash
hd context --usage
```

If context is high (>80%), prepare for handoff:
- Summarize current state
- Note any pending work
- Write handoff to totem state

This enables the Shaman to burn and respawn cleanly."""

[[steps]]
id = "loop-or-exit"
title = "Burn and respawn or loop"
needs = ["context-check"]
description = """
Burn and let daemon respawn, or exit if context high.

Decision point at end of scout cycle:

If context is LOW:
Use await-signal with exponential backoff to wait for activity:

```bash
hd totem step await-signal --agent-bead hq-shaman \
  --backoff-base 60s --backoff-mult 2 --backoff-max 10m
```

This command:
1. Subscribes to `rl activity --follow` (relics activity feed)
2. Returns IMMEDIATELY when any relics activity occurs
3. If no activity, times out with exponential backoff:
   - First timeout: 60s
   - Second timeout: 120s
   - Third timeout: 240s
   - ...capped at 10 minutes max
4. Tracks `idle:N` label on hq-shaman bead for backoff state

**On signal received** (activity detected):
Reset the idle counter and start next scout cycle:
```bash
hd agent state hq-shaman --set idle=0
```
Then return to inbox-check step.

**On timeout** (no activity):
The idle counter was auto-incremented. Continue to next scout cycle
(the longer backoff will apply next time). Return to inbox-check step.

**Why this approach?**
- Any `hd` or `bd` command triggers relics activity, waking the Shaman
- Idle towns let the Shaman sleep longer (up to 10 min between patrols)
- Active work wakes the Shaman immediately via the feed
- No polling or fixed sleep intervals

If context is HIGH:
- Write state to persistent storage
- Exit cleanly
- Let the daemon orchestrator respawn a fresh Shaman

The daemon ensures Shaman is always running:
```bash
# Daemon respawns on exit
hd daemon status
```

This enables infinite scout duration via context-aware respawning."""

